{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karla\\PycharmProjects\\gender_linguistics_on_ParlaMint\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "%cd ..\n",
    "# I need this to access modules from the main folder. Do not move this comment up into the same line\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import swifter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "from scipy import stats as st\n",
    "\n",
    "from generate_dataframe import generate_sentences_and_meta_df_from_multiple_files\n",
    "from load_saved_dataframe import load_saved_df\n",
    "from numerals import *\n",
    "from concordance import *\n",
    "from helper_methods import try_apply, drop_na_with_count\n",
    "from environment_constants import APPROXIMATORS"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# loading\n",
    "load_path = None # \"C:/Users/karla/Desktop/Zula_Data_all_in_one/{save_name}.csv\"\n",
    "\n",
    "# generating\n",
    "number_of_files = None # set to None to use all files, set to n<1795 to use n files\n",
    "random_seed = 1341995\n",
    "\n",
    "# dropping undesired data\n",
    "int_lower_threshold = 2500 # set to None to keep all ints, set to n to drop all ints with values < n\n",
    "drop_time_of_day: bool = True\n",
    "\n",
    "# saving?\n",
    "saving: bool = True\n",
    "save_name = \"2023-03-15_complete\"\n",
    "\n",
    "figures_save_path = \"C:/Users/karla/My Drive/Uni/LMU/Englisch/Zula/figures\"\n",
    "validity_save_path = \"C:/Users/karla/My Drive/Uni/LMU/Englisch/Zula/validity\"\n",
    "qualitative_analysis_save_path = \"C:/Users/karla/My Drive/Uni/LMU/Englisch/Zula/qualitative_analysis\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load / Generate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Generating Dataframe:   0%|          | 0/1795 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4643773bba9245478a635536c05a30c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if load_path:\n",
    "    df = load_saved_df(load_path)\n",
    "else:\n",
    "    df = generate_sentences_and_meta_df_from_multiple_files(number_of_files=number_of_files, random_seed=random_seed)\n",
    "    if saving:\n",
    "        df.to_csv(f\"C:/Users/karla/Desktop/Zula_Data_all_in_one/{save_name}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of sentences: 852883\n",
      "#sentences_dropped_due_to_original_nan: 3965\n"
     ]
    }
   ],
   "source": [
    "n_sentences = df.shape[0]\n",
    "print(f\"total # of sentences: {n_sentences}\")\n",
    "\n",
    "drops_per_func_in_sentences = {}\n",
    "\n",
    "df, drops_per_func_in_sentences['missing values in dataset'] = drop_na_with_count(df)\n",
    "print(f\"#sentences_dropped_due_to_original_nan: {drops_per_func_in_sentences['missing values in dataset']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Numerals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying group_nums\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/848918 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0b0bf954c074999987f81860dd210b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying parse_num_groups\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/838503 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68e421496c854ea0ac434fcef6a149de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying num_list\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/829307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e0aa3ff8471419faed0583d3d059d05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             drop_reason | #sentences_dropped\n",
      "=============================================\n",
      "missing values in dataset | 3965\n",
      "       group_nums failed | 10415\n",
      " parse_num_groups failed | 9196\n",
      "         num_list failed | 0\n"
     ]
    }
   ],
   "source": [
    "func_arg_res = [(group_nums, 'sentence', 'sentence_grouped_nums'),\n",
    "             (parse_num_groups, 'sentence_grouped_nums', 'sentence_parsed_num_groups'),\n",
    "             (num_list, 'sentence_parsed_num_groups', 'NUMs')]\n",
    "            # function, argument_column, result_column\n",
    "\n",
    "for func, arg_col, res_col in func_arg_res:\n",
    "    func_name = func.__name__\n",
    "    print(f\"Applying {func_name}\")\n",
    "    df[res_col] = df[arg_col].swifter.apply((lambda c: try_apply(func, c)))\n",
    "    df, drops_per_func_in_sentences[f\"{func_name} failed\"] = drop_na_with_count(df)\n",
    "\n",
    "print(\"drop_reason\".rjust(24)+\" | #sentences_dropped\"+\"\\n\"+(\"=\"*45))\n",
    "for func_name, drops in drops_per_func_in_sentences.items():\n",
    "    print(func_name.rjust(24)+f\" | {drops}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#numbers: 1241728\n"
     ]
    }
   ],
   "source": [
    "df = df.explode('NUMs').reset_index(drop=True)\n",
    "df['num_index'], placeholder = zip(*df['NUMs'])\n",
    "(df['num_as_str'], df['num_value']) = zip(*placeholder)\n",
    "\n",
    "n_numbers = df.shape[0]\n",
    "print(f\"#numbers: {n_numbers}\")\n",
    "\n",
    "drops_per_func_in_numbers = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/1241728 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e26ae513a734b6db0474b92c8e9e7a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#numbers_dropped_by_find_roundedness: 7107\n"
     ]
    }
   ],
   "source": [
    "df['is_float-like'], df['n_proper_digits'], df['n_zeroes'], df['n_decimals'] = zip(*df['num_as_str'].swifter.apply(lambda cell: try_apply(find_roundedness, cell)))\n",
    "\n",
    "df, drops_per_func_in_numbers['find_roundedness failed'] = drop_na_with_count(df)\n",
    "\n",
    "print(f\"#numbers_dropped_by_find_roundedness: {drops_per_func_in_numbers['find_roundedness failed']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karla\\AppData\\Local\\Temp/ipykernel_10408/109289483.py:16: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[drop_mask].sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/ints_below_threshold\")\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexingError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_10408/109289483.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;31m# save sample of numbers that have not been dropped\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m     \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdrop_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrandom_seed\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{validity_save_path}/ints_below_threshold\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[0mafter_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3794\u001B[0m         \u001B[1;31m# Do we have a (boolean) 1d indexer?\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3795\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_bool_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3796\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_bool_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3797\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3798\u001B[0m         \u001B[1;31m# We are left with two options: a single key, and a collection of keys,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m_getitem_bool_array\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3847\u001B[0m         \u001B[1;31m# check_bool_indexer will throw exception if Series key cannot\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3848\u001B[0m         \u001B[1;31m# be reindexed to match DataFrame rows\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3849\u001B[1;33m         \u001B[0mkey\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_bool_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3850\u001B[0m         \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3851\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_take_with_is_copy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36mcheck_bool_indexer\u001B[1;34m(index, key)\u001B[0m\n\u001B[0;32m   2550\u001B[0m         \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_indexer_for\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2551\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2552\u001B[1;33m             raise IndexingError(\n\u001B[0m\u001B[0;32m   2553\u001B[0m                 \u001B[1;34m\"Unalignable boolean Series provided as \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2554\u001B[0m                 \u001B[1;34m\"indexer (index of the boolean Series and of \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexingError\u001B[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "# we only want to keep all float-likes and those ints that have values of 2500 or more\n",
    "# therefore, get rid of all integers with value of less than 2500\n",
    "# keep track of number of dropped numbers\n",
    "# save sample of dropped and not-dropped numbers to check validity of pipeline\n",
    "if int_lower_threshold is not None:\n",
    "    before_size = df.shape[0]\n",
    "\n",
    "    drop_mask = ((df['is_float-like'] == False) & (df['num_value'] < int_lower_threshold))\n",
    "\n",
    "    # save sample of numbers that will be dropped\n",
    "    df[drop_mask].sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/ints_below_threshold\")\n",
    "\n",
    "    df = df.drop(df[drop_mask].index).reset_index(drop=True)\n",
    "\n",
    "    # save sample of numbers that have not been dropped\n",
    "    df.sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/ints_below_threshold\")\n",
    "\n",
    "    after_size = df.shape[0]\n",
    "    print(f\"dropped {before_size-after_size} integers with value of less than 2500\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['absolute_uncertainty'], df['relative_uncertainty'] =zip(*df.swifter.apply(lambda row: find_uncertainty(row), axis=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['is_time_of_day'] = df.apply(lambda row: is_time_of_day(row), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now drop all numbers indicating the time of day, e.g. \"10.30 pm\"\n",
    "# keep track of number of dropped numbers\n",
    "# save sample of dropped and not-dropped numbers to check validity of pipeline\n",
    "if drop_time_of_day:\n",
    "    before_size = df.shape[0]\n",
    "\n",
    "    drop_mask = df['is_time_of_day']\n",
    "\n",
    "    # save sample of numbers that have not been dropped\n",
    "    df[drop_mask].sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/times_of_day\")\n",
    "\n",
    "    df = df.drop(df[drop_mask].index).reset_index(drop=True)\n",
    "\n",
    "    # save sample of numbers that have not been dropped\n",
    "    df.sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/not_times_of_day\")\n",
    "\n",
    "    after_size = df.shape[0]\n",
    "    print(f\"dropped {before_size-after_size} numbers indicating the time of day, e.g. '10.30 pm'\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['is_about_money'] = df.apply(lambda row: is_about_money(row), axis=1)\n",
    "\n",
    "# save samples\n",
    "df[df['is_about_money']].sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/is_about_money\")\n",
    "df[df['is_about_money'] == False].sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/is_not_about_money\")\n",
    "\n",
    "\n",
    "df['has_approximator'], df['approximators'] = zip(*df.apply(lambda row: has_approximator(row), axis=1))\n",
    "\n",
    "# save samples\n",
    "df[df['has_approximator']].sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/with_approximator\")\n",
    "df[df['has_approximator'] == False].sample(20, random_state=random_seed, axis=0).to_csv(f\"{validity_save_path}/without_approximator\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Drops in Loading and Parsing Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropped Sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drop_sentences = list(drops_per_func_in_sentences.values())\n",
    "drop_sentences.insert(0, n_sentences - sum(drop_sentences))\n",
    "drop_sentences_labels = list(drops_per_func_in_sentences.keys())\n",
    "drop_sentences_labels.insert(0, 'intact sentences')\n",
    "\n",
    "plt.pie(drop_sentences, startangle=90, counterclock=False, wedgeprops = {'linewidth': 0})\n",
    "plt.legend(drop_sentences_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(f\"{figures_save_path}/piecharts/dropped_sentences.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropped Numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drop_numbers = list(drops_per_func_in_numbers.values())\n",
    "drop_numbers.insert(0, n_numbers - sum(drop_numbers))\n",
    "drop_numbers_labels = list(drops_per_func_in_numbers.keys())\n",
    "drop_numbers_labels.insert(0, 'intact numbers')\n",
    "\n",
    "plt.pie(drop_numbers, startangle=90, counterclock=False, wedgeprops = {'linewidth': 0})\n",
    "plt.legend(drop_numbers_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(f\"{figures_save_path}/piecharts/dropped_numbers.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sampling Dataset to Check Validity of Preprocessing and Analysis Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_df = df.sample(n=100, random_state=random_seed, axis=0)\n",
    "sample_df['num_as_str'] = sample_df['num_as_str'].apply(lambda s: \"'\"+s)\n",
    "for full_sentence in ['sentence', 'sentence_grouped_nums', 'sentence_parsed_num_groups']:\n",
    "    sample_df[full_sentence] = sample_df[full_sentence].apply(lambda s: s['form'])\n",
    "sample_df.to_csv(f\"{qualitative_analysis_save_path}/sample_for_limitations_section.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = {'decimal numbers': df[df['is_float-like'] == True],\n",
    "       'integers': df[df['is_float-like'] == False]\n",
    "       }\n",
    "\n",
    "binary_independent_variables = {'is_upper_house': ('house', 'lower house', 'upper house'),\n",
    "                    'is_chairperson': ('speaker role', 'regular', 'chairperson'),\n",
    "                    'is_mp': ('speaker type', 'not MP', 'MP'),\n",
    "                    'is_female': ('gender', 'male', 'female'),\n",
    "                    'is_coalition': ('party status', 'opposition', 'coalition'),\n",
    "                    'is_about_money': ('counted entity', 'not money', 'money'),\n",
    "                    'has_approximator': ('has an approximator', 'with', 'without')\n",
    "                    }\n",
    "                    # column_name, variable_name, value0 (False), value1 (True)\n",
    "\n",
    "dependent_variables = {'num_value': 'number value',\n",
    "                       # 'n_proper_digits': 'number of proper digits',\n",
    "                       # 'n_zeroes': 'number of zeros',\n",
    "                       # 'absolute_uncertainty': 'absolute uncertainty',\n",
    "                       'relative_uncertainty': 'relative uncertainty'\n",
    "                       }\n",
    "\n",
    "max_dv_name_len = max((len(_dv) for _dv in dependent_variables))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scatterplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "for df_name, _df in dfs.items():\n",
    "\n",
    "    for biv_key, (biv_name, biv_false_value, biv_true_value) in binary_independent_variables.items():\n",
    "\n",
    "        data = _df.copy()\n",
    "        data[biv_name] = _df[biv_key].replace({False: biv_false_value, True: biv_true_value, 'n/a': 'other'}, inplace=False)\n",
    "\n",
    "        x_axis = 'num_value'\n",
    "        y_axis = 'relative_uncertainty'\n",
    "\n",
    "        sns.scatterplot(x=x_axis, y=y_axis, hue=biv_name, data=data, style=biv_name) #alpha=0.2,\n",
    "\n",
    "        plt.title(f\"distribution of {df_name} by {biv_name}\")\n",
    "        plt.xlabel('number value')\n",
    "        plt.ylabel('relative uncertainty')\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "        plt.xscale('log')\n",
    "        plt.savefig(f\"{figures_save_path}/scatterplots/{df_name}--{biv_name}--x-{x_axis}--y-{y_axis}.png\",\n",
    "                    dpi=300)\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Histograms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: fix width of bars\n",
    "#  https://stackoverflow.com/questions/38234545/multiple-histograms-with-logarithmic-x-scale\n",
    "#  https://stackoverflow.com/questions/30551694/logarithmic-multi-sequenz-plot-with-equal-bar-widths\n",
    "#  or do step diagram instead\n",
    "#  also consider different y-axes to normalize https://stackoverflow.com/a/47750425/18420741\n",
    "# TODO: AttributeError: 'Rectangle' object has no property 'labels'\n",
    "# TODO: make sure max_number_value is part of diagram!\n",
    "# TODO: only unit fractions for relative_uncertainty\n",
    "\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "for df_name, _df in dfs.items():\n",
    "\n",
    "    for biv_key, (biv_name, biv_false_value, biv_true_value) in binary_independent_variables.items():\n",
    "\n",
    "        for dv, dv_name in dependent_variables.items():\n",
    "\n",
    "            distribution_biv_true = _df[_df[biv_key] == True][dv]\n",
    "            distribution_biv_false = _df[_df[biv_key] == False][dv]\n",
    "            distribution_biv_other = _df[(_df[biv_key] != True) & (_df[biv_key] != False)][dv]\n",
    "\n",
    "            if distribution_biv_other.shape[0] == 0:\n",
    "                distributions = [distribution_biv_true, distribution_biv_false]\n",
    "                labels = [biv_true_value, biv_false_value]\n",
    "            else:\n",
    "                distributions = [distribution_biv_true, distribution_biv_false, distribution_biv_other]\n",
    "                labels = [biv_true_value, biv_false_value, 'other']\n",
    "\n",
    "\n",
    "            for normed in (True, False):\n",
    "                if normed:\n",
    "                    plt.title(f\"{df_name} by {biv_name} - normalized\")\n",
    "                    save_path = f\"{figures_save_path}/histograms/{df_name}-{dv}-{biv_name}-normalized.png\"\n",
    "                    plt.ylabel(\"percentage\")\n",
    "                else:\n",
    "                    plt.title(f\"{df_name} by {biv_name}\")\n",
    "                    save_path = f\"{figures_save_path}/histograms/{df_name}-{dv}-{biv_name}-not_normalized.png\"\n",
    "                    plt.ylabel(\"count\")\n",
    "\n",
    "                plt.xlabel(dv_name)\n",
    "\n",
    "                if dv in {'num_value', 'absolute_uncertainty'}:\n",
    "                    plt.xscale('log')\n",
    "                    bins = [5**i for i in range(30)]\n",
    "                elif dv == 'relative_uncertainty':\n",
    "                    bins = [0.05*i for i in range(21)]\n",
    "                else:\n",
    "                    bins = range(15)\n",
    "\n",
    "                if normed:\n",
    "                    plt.hist(distributions, bins=bins, weights=[np.ones(len(dist)) / len(dist) for dist in distributions]) # labels=labels,\n",
    "                    plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "                else:\n",
    "                    plt.hist(distributions, bins=bins) #, label=labels) # , histtype='step')\n",
    "\n",
    "                plt.legend(title=biv_name, labels=labels,  loc='upper right')\n",
    "\n",
    "                plt.savefig(\n",
    "                    save_path,\n",
    "                    dpi=300,\n",
    "                    bbox_inches=\"tight\")\n",
    "                plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boxplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GAP_BETWEEN_CATEGORIES = 0.5  # How much extra space should be between different categories\n",
    "BOX_PLOT_STEP = 0.7  # How much to increment x for each box plot. Boxplots have a default width of 0.5\n",
    "CATEGORY_LABEL_POSITION = 0.35  # How much, relative to the height of the whole figure, should the category label be below the x-axis\n",
    "\n",
    "FONT_SIZE_AXIS_LABEL = 20\n",
    "FONT_SIZE_TITLE = 20\n",
    "FONT_SIZE_X_TICK = 12\n",
    "\n",
    "PLOT_DEFAULT_WIDTH = 2  # Approximate width (in inches) of an empty plot\n",
    "BOX_PLOT_WIDTH = 1  # Approximate width (in inches) that the plot grows when a boxplot is added\n",
    "\n",
    "# Custom adjustment of column labels. column_name_in_dataframe => new_column_name\n",
    "COLUMN_LABEL_MAPPING = {\n",
    "    \"party status: other\": \"other\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_dataframe_grouping(_df) -> Tuple[List[float], List[float]]:\n",
    "    box_plot_x_positions = []\n",
    "    category_separator_x_positions = []  # Positions of vertical lines that visualize where the next category starts\n",
    "\n",
    "    _prev_col_category = None\n",
    "    _next_x_position = -BOX_PLOT_STEP\n",
    "    for col in _df.columns:\n",
    "        col_category = None\n",
    "\n",
    "        if col == 'total':\n",
    "            # Special case for 'total' column which is not listed in binary_independent_variables dict\n",
    "            col_category = 'total'\n",
    "        elif col in {'party status: other', 'other'}:\n",
    "            col_category = _prev_col_category\n",
    "        else:\n",
    "            # Try to find column name in the binary_independent_variables dictionary\n",
    "            # This gives us the category that this column belongs to\n",
    "            for var_category, var_values in binary_independent_variables.items():\n",
    "                if col in var_values:\n",
    "                    col_category = var_category\n",
    "\n",
    "        assert col_category is not None, f\"Could not find category for column {col}\"\n",
    "\n",
    "        # Create a small gap between box plots if the next boxplot belongs to a different category\n",
    "        if _prev_col_category is not None and col_category != _prev_col_category:\n",
    "            category_separator_x_positions.append(_next_x_position + (BOX_PLOT_STEP + GAP_BETWEEN_CATEGORIES) / 2)\n",
    "            _next_x_position += GAP_BETWEEN_CATEGORIES\n",
    "\n",
    "        _next_x_position += BOX_PLOT_STEP\n",
    "        _prev_col_category = col_category\n",
    "        box_plot_x_positions.append(_next_x_position)\n",
    "\n",
    "    return box_plot_x_positions, category_separator_x_positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Single Categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "for df_name, _df in dfs.items():\n",
    "\n",
    "    for dv, dv_name in dependent_variables.items():\n",
    "        plt.title(f\"distribution of {dv_name}\")\n",
    "\n",
    "        for biv_key, (biv_name, biv_false_value, biv_true_value) in binary_independent_variables.items():\n",
    "\n",
    "            combined_df = _df[dv].to_frame(name='total') #.rename(columns={dv: 'total'})\n",
    "\n",
    "            combined_df[biv_true_value] = _df[_df[biv_key] == True][dv]\n",
    "            combined_df[biv_false_value] = _df[_df[biv_key] == False][dv]\n",
    "\n",
    "            distribution_biv_other = _df[(_df[biv_key] != True) & (_df[biv_key] != False)][dv]\n",
    "            if distribution_biv_other.shape[0] != 0:\n",
    "                combined_df['other'] = distribution_biv_other\n",
    "\n",
    "            box_plot_x_positions, category_separator_x_positions = compute_dataframe_grouping(combined_df)\n",
    "\n",
    "            figwidth = PLOT_DEFAULT_WIDTH + len(combined_df.columns) * BOX_PLOT_WIDTH\n",
    "\n",
    "            combined_df.plot(kind='box', rot=45, showfliers=False, positions=box_plot_x_positions, widths=0.5, figsize=(figwidth, 6))\n",
    "\n",
    "\n",
    "            plt.title(f\"{df_name} by {biv_name}\")\n",
    "            plt.ylabel(dv_name)\n",
    "\n",
    "            # Set font sizes\n",
    "            plt.gca().yaxis.label.set_fontsize(FONT_SIZE_AXIS_LABEL)\n",
    "            plt.gca().title.set_fontsize(FONT_SIZE_TITLE)\n",
    "            for x_tick_label in plt.gca().get_xticklabels():\n",
    "                x_tick_label.set_fontsize(FONT_SIZE_X_TICK)\n",
    "\n",
    "            # Plot separators between categories\n",
    "            for category_separator_x_position in category_separator_x_positions:\n",
    "                plt.axvline(category_separator_x_position, linestyle='--', color='darkgray')\n",
    "\n",
    "            # change y_axis ticks so they don't say 1e6 at the top of the y_axis and coefficients on the ticks\n",
    "            # instead have it say million if the value is in the millions\n",
    "            current_y_ticks = plt.gca().get_yticks()\n",
    "            if max(current_y_ticks) > 10 ** 6:\n",
    "                plt.gca().set_yticklabels(['{:.0f}M'.format(x/10**6)  for x in current_y_ticks])\n",
    "\n",
    "            plt.savefig(f\"{figures_save_path}/boxplots/{df_name}-{dv}-{biv_name}.png\",\n",
    "                        dpi=300,\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "# for saving with log y-scale activate the following lines:\n",
    "#            plt.yscale('log')\n",
    "\n",
    "#            plt.savefig(f\"{figures_save_path}/boxplots/{df_name}-{dv}-{biv_name}-log_scale.png\",\n",
    "#                        dpi=300,\n",
    "#                        bbox_inches=\"tight\")\n",
    "\n",
    "#            plt.show()\n",
    "            plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### All-in-One with normal money"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "# TODO: group by category @Tobias\n",
    "\n",
    "for df_name, _df in dfs.items():\n",
    "\n",
    "    for dv, dv_name in dependent_variables.items():\n",
    "        combined_df = _df[dv].to_frame(name='total')\n",
    "\n",
    "        # Select only columns listed in binary_independent_variables\n",
    "        for biv_key, (biv_name, biv_false_value, biv_true_value) in binary_independent_variables.items():\n",
    "\n",
    "            combined_df[biv_true_value] = _df[_df[biv_key] == True][dv]\n",
    "            combined_df[biv_false_value] = _df[_df[biv_key] == False][dv]\n",
    "\n",
    "            distribution_biv_other = _df[(_df[biv_key] != True) & (_df[biv_key] != False)][dv]\n",
    "            if distribution_biv_other.shape[0] != 0:\n",
    "                combined_df[f\"{biv_name}: other\"] = distribution_biv_other\n",
    "\n",
    "        box_plot_x_positions, category_separator_x_positions = compute_dataframe_grouping(combined_df)\n",
    "        column_names = combined_df.columns\n",
    "        column_names = [COLUMN_LABEL_MAPPING[col_name]\n",
    "                        if col_name in COLUMN_LABEL_MAPPING\n",
    "                        else col_name\n",
    "                        for col_name\n",
    "                        in column_names]\n",
    "        combined_df.columns = column_names\n",
    "\n",
    "        combined_df.plot(kind='box', rot=45, figsize=(20, 4.8), showfliers=False, positions=box_plot_x_positions)\n",
    "\n",
    "        # Plot separators between categories\n",
    "        for category_separator_x_position in category_separator_x_positions:\n",
    "            plt.axvline(category_separator_x_position, linestyle='--', color='darkgray')\n",
    "\n",
    "        plt.title(f\"{df_name}\")\n",
    "        plt.ylabel(dv_name)\n",
    "\n",
    "        # Set font sizes\n",
    "        plt.gca().yaxis.label.set_fontsize(FONT_SIZE_AXIS_LABEL)\n",
    "        plt.gca().title.set_fontsize(FONT_SIZE_TITLE)\n",
    "        for x_tick_label in plt.gca().get_xticklabels():\n",
    "            x_tick_label.set_fontsize(FONT_SIZE_X_TICK)\n",
    "\n",
    "\n",
    "        # change y_axis ticks so they don't say 1e6 at the top of the y_axis and coefficients on the ticks\n",
    "        # instead have it say million if the value is in the millions\n",
    "        current_y_ticks = plt.gca().get_yticks()\n",
    "        if max(current_y_ticks) > 10 ** 6:\n",
    "            plt.gca().set_yticklabels(['{:.0f}M'.format(x/10**6)  for x in current_y_ticks])\n",
    "\n",
    "        # Add category labels centered below the respective column names\n",
    "        for i_category, (category, col_names) in enumerate(binary_independent_variables.items()):\n",
    "            if i_category < len(binary_independent_variables.keys()) - 1:\n",
    "                # Position of category label is computed by taking the middle positions of the\n",
    "                # left and right category separator line\n",
    "                category_label_x_position = (category_separator_x_positions[i_category] + category_separator_x_positions[i_category + 1]) / 2\n",
    "            else:\n",
    "                # Special case for the last category label since we don't have a separator line to the right of that\n",
    "                category_label_x_position = category_separator_x_positions[i_category] + GAP_BETWEEN_CATEGORIES / 2 + (len(col_names) - 1) * BOX_PLOT_STEP / 2\n",
    "\n",
    "            category_label_y_position = -CATEGORY_LABEL_POSITION* current_y_ticks[-1]\n",
    "            category_label = col_names[0]\n",
    "            plt.text(category_label_x_position, category_label_y_position, col_names[0], horizontalalignment='center', fontsize=15)\n",
    "\n",
    "\n",
    "        plt.savefig(f\"{figures_save_path}/boxplots/{df_name}-{dv}-all_in_one.png\",\n",
    "                    dpi=300,\n",
    "                    bbox_inches=\"tight\")\n",
    "\n",
    "# for saving with log y-scale activate the following lines:\n",
    "#        plt.yscale('log')\n",
    "\n",
    "#        plt.savefig(f\"{figures_save_path}/boxplots/{df_name}-{dv}-all_in_one-log_scale.png\",\n",
    "#                    dpi=300,\n",
    "#                    bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "#        plt.show()\n",
    "        plt.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Qualitative Analysis: Generate .csv files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns_to_investigate = ['sent_id', 'Speaker_name', 'is_coalition', 'is_mp', 'is_female', 'is_upper_house', 'is_chairperson', 'sentence','num_value', 'is_float-like', 'relative_uncertainty', 'is_about_money', 'has_approximator', 'approximators']\n",
    "\n",
    "# high number values\n",
    "df[columns_to_investigate].sort_values(by='num_value', ascending=False, inplace=False).iloc[:100].to_csv(f\"{qualitative_analysis_save_path}/high_number_values.csv\")\n",
    "\n",
    "# negative number values\n",
    "df[columns_to_investigate][df['num_value'] < 0].to_csv(f\"{qualitative_analysis_save_path}/negative_number_values.csv\")\n",
    "\n",
    "# low relative uncertainty\n",
    "df[columns_to_investigate].sort_values(by='relative_uncertainty', ascending=True, inplace=False).iloc[:100].to_csv(f\"{qualitative_analysis_save_path}/low_relative_uncertainty.csv\")\n",
    "\n",
    "# high relative uncertainty\n",
    "df[columns_to_investigate].sort_values(by='relative_uncertainty', ascending=False, inplace=False).iloc[:100].to_csv(f\"{qualitative_analysis_save_path}/low_relative_uncertainty.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Shit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['is_float-like']][columns_to_investigate].sort_values(by='num_value', ascending=False, inplace=False).iloc[:100].to_csv(f\"{qualitative_analysis_save_path}/float-likes--high_number_values.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['is_about_money']].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-Linguistics-py",
   "language": "python",
   "display_name": "Python [conda env:Linguistics] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
