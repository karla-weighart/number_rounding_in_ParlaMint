{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karla\\PycharmProjects\\gender_linguistics_on_ParlaMint\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "%cd ..\n",
    "# I need this to access modules from the main folder. Do not move this comment up into the same line\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import swifter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "from scipy import stats as st\n",
    "\n",
    "from generate_dataframe import generate_sentences_and_meta_df_from_multiple_files\n",
    "from load_saved_dataframe import load_saved_df\n",
    "from numerals import *\n",
    "from concordance import *\n",
    "from helper_methods import try_apply, drop_na_with_count\n",
    "from environment_constants import APPROXIMATORS"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# loading\n",
    "load_path = None # \"C:/Users/karla/Desktop/Zula_Data_all_in_one/{save_name}.csv\"\n",
    "\n",
    "# generating\n",
    "number_of_files = 1\n",
    "random_seed = 1341995\n",
    "\n",
    "# dropping undesired data\n",
    "int_lower_threshold = 2500\n",
    "drop_time_of_day = True\n",
    "\n",
    "# saving?\n",
    "saving = False\n",
    "save_name = \"2023-03-06\"\n",
    "\n",
    "figures_save_path = \"C:/Users/karla/My Drive/Uni/LMU/Englisch/Zula/figures\"\n",
    "qualitative_analysis_save_path = \"C:/Users/karla/My Drive/Uni/LMU/Englisch/Zula/qualitative_analysis\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load / Generate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Generating Dataframe:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00d64597d7e8479e98c8168f4e40391f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if load_path:\n",
    "    df = load_saved_df(load_path)\n",
    "else:\n",
    "    df = generate_sentences_and_meta_df_from_multiple_files(number_of_files=number_of_files, random_seed=random_seed)\n",
    "    if saving:\n",
    "        df.to_csv(f\"C:/Users/karla/Desktop/Zula_Data_all_in_one/{save_name}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of sentences: 540\n",
      "#sentences_dropped_due_to_original_nan: 0\n"
     ]
    }
   ],
   "source": [
    "n_sentences = df.shape[0]\n",
    "print(f\"total # of sentences: {n_sentences}\")\n",
    "\n",
    "drops_per_func_in_sentences = {}\n",
    "\n",
    "df, drops_per_func_in_sentences['missing values in dataset'] = drop_na_with_count(df)\n",
    "print(f\"#sentences_dropped_due_to_original_nan: {drops_per_func_in_sentences['missing values in dataset']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Numerals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying group_nums\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/540 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9623f5754a84d1b8769c8762e5b4c39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying parse_num_groups\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/531 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8facec0b429b41b29d6e42d0af800697"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying num_list\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/524 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de91bdbd42d94f70898dfbab0edcd1af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             drop_reason | #sentences_dropped\n",
      "=============================================\n",
      "missing values in dataset | 0\n",
      "       group_nums failed | 9\n",
      " parse_num_groups failed | 7\n",
      "         num_list failed | 0\n"
     ]
    }
   ],
   "source": [
    "func_arg_res = [(group_nums, 'sentence', 'sentence_grouped_nums'),\n",
    "             (parse_num_groups, 'sentence_grouped_nums', 'sentence_parsed_num_groups'),\n",
    "             (num_list, 'sentence_parsed_num_groups', 'NUMs')]\n",
    "            # function, argument_column, result_column\n",
    "\n",
    "for func, arg_col, res_col in func_arg_res:\n",
    "    func_name = func.__name__\n",
    "    print(f\"Applying {func_name}\")\n",
    "    df[res_col] = df[arg_col].swifter.apply((lambda c: try_apply(func, c)))\n",
    "    df, drops_per_func_in_sentences[f\"{func_name} failed\"] = drop_na_with_count(df)\n",
    "\n",
    "print(\"drop_reason\".rjust(24)+\" | #sentences_dropped\"+\"\\n\"+(\"=\"*45))\n",
    "for func_name, drops in drops_per_func_in_sentences.items():\n",
    "    print(func_name.rjust(24)+f\" | {drops}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#numbers: 897\n"
     ]
    }
   ],
   "source": [
    "df = df.explode('NUMs').reset_index(drop=True)\n",
    "df['num_index'], placeholder = zip(*df['NUMs'])\n",
    "(df['num_as_str'], df['num_value']) = zip(*placeholder)\n",
    "\n",
    "n_numbers = df.shape[0]\n",
    "print(f\"#numbers: {n_numbers}\")\n",
    "\n",
    "drops_per_func_in_numbers = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/897 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46b491a555af433ab728b1e7206ab95b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#numbers_dropped_by_find_roundedness: 1\n"
     ]
    }
   ],
   "source": [
    "df['is_float-like'], df['n_proper_digits'], df['n_zeroes'], df['n_decimals'] = zip(*df['num_as_str'].swifter.apply(lambda cell: try_apply(find_roundedness, cell)))\n",
    "\n",
    "df, drops_per_func_in_numbers['find_roundedness failed'] = drop_na_with_count(df)\n",
    "\n",
    "print(f\"#numbers_dropped_by_find_roundedness: {drops_per_func_in_numbers['find_roundedness failed']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we only want to keep all float-likes and those ints that have values of 2500 or more\n",
    "# therefore, get rid of all integers with value of less than 2500\n",
    "if int_lower_threshold is not None:\n",
    "    before_size = df.shape[0]\n",
    "\n",
    "    drop_mask = ((df['is_float-like'] == False) & (df['num_value'] < int_lower_threshold))\n",
    "    df = df.drop(df[drop_mask].index).reset_index(drop=True)\n",
    "\n",
    "    after_size = df.shape[0]\n",
    "    print(f\"dropped {before_size-after_size} integers with value of less than 2500\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/896 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20ea83005d2749b5b403789f070dafa0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['absolute_uncertainty'], df['relative_uncertainty'] =zip(*df.swifter.apply(lambda row: find_uncertainty(row), axis=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['is_time_of_day'] = df.apply(lambda row: is_time_of_day(row), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "51",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m    390\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 391\u001B[1;33m                     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_range\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    392\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: 51 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15580/1462291075.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# df['has_approximator'], df['approximators'] = zip(*df.apply(lambda row: has_approximator(row), axis=1))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mhas_approximator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   9563\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   9564\u001B[0m         )\n\u001B[1;32m-> 9565\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"apply\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   9566\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   9567\u001B[0m     def applymap(\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    744\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_raw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    745\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 746\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    747\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    748\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    871\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    872\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 873\u001B[1;33m         \u001B[0mresults\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mres_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_series_generator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    874\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    875\u001B[0m         \u001B[1;31m# wrap results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseries_gen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m                 \u001B[1;31m# ignore SettingWithCopy here in case the user mutates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m                 \u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    891\u001B[0m                     \u001B[1;31m# If we have a view on v, we need to make a copy because\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15580/1462291075.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# df['has_approximator'], df['approximators'] = zip(*df.apply(lambda row: has_approximator(row), axis=1))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mhas_approximator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\PycharmProjects\\gender_linguistics_on_ParlaMint\\numerals.py\u001B[0m in \u001B[0;36mhas_approximator\u001B[1;34m(row, approximators, before_gap, after_gap)\u001B[0m\n\u001B[0;32m    339\u001B[0m             \u001B[1;31m# if so, add the current approximator to the relevant entry in the result dict found_approximators\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    340\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mfirst_word_index\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfirst_word_min_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfirst_word_max_index\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 341\u001B[1;33m                 if all([sentence_df['form'][first_word_index + i] == approximator[i] for i in\n\u001B[0m\u001B[0;32m    342\u001B[0m                         range(approximator_n_words)]):\n\u001B[0;32m    343\u001B[0m                     \u001B[0mfound_approximators\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mapproximator_type\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mapproximator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\gender_linguistics_on_ParlaMint\\numerals.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    339\u001B[0m             \u001B[1;31m# if so, add the current approximator to the relevant entry in the result dict found_approximators\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    340\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mfirst_word_index\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfirst_word_min_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfirst_word_max_index\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 341\u001B[1;33m                 if all([sentence_df['form'][first_word_index + i] == approximator[i] for i in\n\u001B[0m\u001B[0;32m    342\u001B[0m                         range(approximator_n_words)]):\n\u001B[0;32m    343\u001B[0m                     \u001B[0mfound_approximators\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mapproximator_type\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mapproximator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    979\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    980\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mkey_is_scalar\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 981\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    982\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    983\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_hashable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36m_get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1087\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1088\u001B[0m         \u001B[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1089\u001B[1;33m         \u001B[0mloc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1090\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_values_for_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1091\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m    391\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_range\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    392\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 393\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    394\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_indexing_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 51"
     ]
    }
   ],
   "source": [
    "# now drop all numbers indicating the time of day, e.g. '10.30 pm'\n",
    "if drop_time_of_day:\n",
    "    before_size = df.shape[0]\n",
    "\n",
    "    drop_mask = df['is_time_of_day']\n",
    "    df = df.drop(df[drop_mask].index).reset_index(drop=True)\n",
    "\n",
    "    after_size = df.shape[0]\n",
    "    print(f\"dropped {before_size-after_size} numbers indicating the time of day, e.g. '10.30 pm\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_time_of_day'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3803\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3804\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'is_time_of_day'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15580/769121185.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# also drop all numbers indicating the time of day, e.g. '10.30 pm'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mdrop_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'is_time_of_day'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdrop_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3803\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3804\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3805\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3806\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3807\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Linguistics\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3804\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3805\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3806\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3807\u001B[0m                 \u001B[1;31m# If we have a listlike key, _check_indexing_error will raise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'is_time_of_day'"
     ]
    }
   ],
   "source": [
    "df['is_about_money'] = df.apply(lambda row: is_about_money(row), axis=1)\n",
    "df['has_approximator'], df['approximators'] = zip(*df.apply(lambda row: has_approximator(row), axis=1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Drops in Loading and Parsing Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropped Sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drop_sentences = list(drops_per_func_in_sentences.values())\n",
    "drop_sentences.insert(0, n_sentences - sum(drop_sentences))\n",
    "drop_sentences_labels = list(drops_per_func_in_sentences.keys())\n",
    "drop_sentences_labels.insert(0, 'intact sentences')\n",
    "\n",
    "plt.pie(drop_sentences, startangle=90, counterclock=False, wedgeprops = {'linewidth': 0})\n",
    "plt.legend(drop_sentences_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(f\"{figures_save_path}/piecharts/dropped_sentences.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropped Numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drop_numbers = list(drops_per_func_in_numbers.values())\n",
    "drop_numbers.insert(0, n_numbers - sum(drop_numbers))\n",
    "drop_numbers_labels = list(drops_per_func_in_numbers.keys())\n",
    "drop_numbers_labels.insert(0, 'intact numbers')\n",
    "\n",
    "plt.pie(drop_numbers, startangle=90, counterclock=False, wedgeprops = {'linewidth': 0})\n",
    "plt.legend(drop_numbers_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(f\"{figures_save_path}/piecharts/dropped_numbers.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sampling Dataset to Check Validity of Preprocessing and Analysis Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_df = df.sample(n=100, random_state=random_seed, axis=0)\n",
    "sample_df['num_as_str'] = sample_df['num_as_str'].apply(lambda s: \"'\"+s)\n",
    "for full_sentence in ['sentence', 'sentence_grouped_nums', 'sentence_parsed_num_groups']:\n",
    "    sample_df[full_sentence] = sample_df[full_sentence].apply(lambda s: s['form'])\n",
    "sample_df.to_csv(f\"{qualitative_analysis_save_path}/sample_for_limitations_section.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = {'decimal numbers': df[df['is_float-like'] == True],\n",
    "       'integers': df[df['is_float-like'] == False]\n",
    "       }\n",
    "\n",
    "binary_independent_variables = {'is_upper_house': ('house', 'lower house', 'upper house'),\n",
    "                    'is_chairperson': ('speaker role', 'regular', 'chairperson'),\n",
    "                    'is_mp': ('speaker type', 'not MP', 'MP'),\n",
    "                    'is_female': ('gender', 'male', 'female'),\n",
    "                    'is_coalition': ('party status', 'opposition', 'coalition'),\n",
    "                    'is_about_money': ('counted entity', 'not money', 'money'),\n",
    "                    'has_approximator': ('has an approximator', 'with', 'without')\n",
    "                    }\n",
    "                    # column_name, variable_name, value0 (False), value1 (True)\n",
    "\n",
    "dependent_variables = {'num_value': 'number value',\n",
    "                       # 'n_proper_digits': 'number of proper digits',\n",
    "                       # 'n_zeroes': 'number of zeros',\n",
    "                       # 'absolute_uncertainty': 'absolute uncertainty',\n",
    "                       'relative_uncertainty': 'relative uncertainty'\n",
    "                       }\n",
    "\n",
    "max_dv_name_len = max((len(_dv) for _dv in dependent_variables))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scatterplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "for df_name, _df in dfs.items():\n",
    "\n",
    "    for biv_key, (biv_name, biv_false_value, biv_true_value) in binary_independent_variables.items():\n",
    "\n",
    "        data = _df.copy()\n",
    "        data[biv_name] = _df[biv_key].replace({False: biv_false_value, True: biv_true_value, 'n/a': 'other'}, inplace=False)\n",
    "\n",
    "        x_axis = 'num_value'\n",
    "        y_axis = 'relative_uncertainty'\n",
    "\n",
    "        sns.scatterplot(x=x_axis, y=y_axis, hue=biv_name, data=data, style=biv_name) #alpha=0.2,\n",
    "\n",
    "        plt.title(f\"distribution of {df_name} by {biv_name}\")\n",
    "        plt.xlabel('number value')\n",
    "        plt.ylabel('relative uncertainty')\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "        plt.xscale('log')\n",
    "        plt.savefig(f\"{figures_save_path}/scatterplots/{df_name}--{biv_name}--x-{x_axis}--y-{y_axis}.png\",\n",
    "                    dpi=300)\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Histograms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: fix width of bars\n",
    "#  https://stackoverflow.com/questions/38234545/multiple-histograms-with-logarithmic-x-scale\n",
    "#  https://stackoverflow.com/questions/30551694/logarithmic-multi-sequenz-plot-with-equal-bar-widths\n",
    "#  or do step diagram instead\n",
    "#  also consider different y-axes to normalize https://stackoverflow.com/a/47750425/18420741\n",
    "# TODO: AttributeError: 'Rectangle' object has no property 'labels'\n",
    "# TODO: make sure max_number_value is part of diagram!\n",
    "\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "for df_name, _df in dfs.items():\n",
    "\n",
    "    for biv_key, (biv_name, biv_false_value, biv_true_value) in binary_independent_variables.items():\n",
    "\n",
    "        for dv, dv_name in dependent_variables.items():\n",
    "\n",
    "            distribution_biv_true = _df[_df[biv_key] == True][dv]\n",
    "            distribution_biv_false = _df[_df[biv_key] == False][dv]\n",
    "            distribution_biv_other = _df[(_df[biv_key] != True) & (_df[biv_key] != False)][dv]\n",
    "\n",
    "            if distribution_biv_other.shape[0] == 0:\n",
    "                distributions = [distribution_biv_true, distribution_biv_false]\n",
    "                labels = [biv_true_value, biv_false_value]\n",
    "            else:\n",
    "                distributions = [distribution_biv_true, distribution_biv_false, distribution_biv_other]\n",
    "                labels = [biv_true_value, biv_false_value, 'other']\n",
    "\n",
    "\n",
    "            for normed in (True, False):\n",
    "                if normed:\n",
    "                    plt.title(f\"{df_name} by {biv_name} - normalized\")\n",
    "                    save_path = f\"{figures_save_path}/histograms/{df_name}-{dv}-{biv_name}-normalized.png\"\n",
    "                    plt.ylabel(\"percentage\")\n",
    "                else:\n",
    "                    plt.title(f\"{df_name} by {biv_name}\")\n",
    "                    save_path = f\"{figures_save_path}/histograms/{df_name}-{dv}-{biv_name}-not_normalized.png\"\n",
    "                    plt.ylabel(\"count\")\n",
    "\n",
    "                plt.xlabel(dv_name)\n",
    "\n",
    "                if dv in {'num_value', 'absolute_uncertainty'}:\n",
    "                    plt.xscale('log')\n",
    "                    bins = [5**i for i in range(30)]\n",
    "                elif dv == 'relative_uncertainty':\n",
    "                    bins = [0.05*i for i in range(21)]\n",
    "                else:\n",
    "                    bins = range(15)\n",
    "\n",
    "                if normed:\n",
    "                    plt.hist(distributions, bins=bins, weights=[np.ones(len(dist)) / len(dist) for dist in distributions]) # labels=labels,\n",
    "                    plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "                else:\n",
    "                    plt.hist(distributions, bins=bins) #, label=labels) # , histtype='step')\n",
    "\n",
    "                plt.legend(title=biv_name, labels=labels,  loc='upper right')\n",
    "\n",
    "                plt.savefig(\n",
    "                    save_path,\n",
    "                    dpi=300,\n",
    "                    bbox_inches=\"tight\")\n",
    "                plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boxplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GAP_BETWEEN_CATEGORIES = 0.5  # How much extra space should be between different categories\n",
    "BOX_PLOT_STEP = 0.7  # How much to increment x for each box plot. Boxplots have a default width of 0.5\n",
    "CATEGORY_LABEL_POSITION = 0.35  # How much, relative to the height of the whole figure, should the category label be below the x-axis\n",
    "\n",
    "FONT_SIZE_AXIS_LABEL = 20\n",
    "FONT_SIZE_TITLE = 20\n",
    "FONT_SIZE_X_TICK = 12\n",
    "\n",
    "PLOT_DEFAULT_WIDTH = 2  # Approximate width (in inches) of an empty plot\n",
    "BOX_PLOT_WIDTH = 1  # Approximate width (in inches) that the plot grows when a boxplot is added\n",
    "\n",
    "# Custom adjustment of column labels. column_name_in_dataframe => new_column_name\n",
    "COLUMN_LABEL_MAPPING = {\n",
    "    \"party status: other\": \"other\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_dataframe_grouping(_df) -> Tuple[List[float], List[float]]:\n",
    "    box_plot_x_positions = []\n",
    "    category_separator_x_positions = []  # Positions of vertical lines that visualize where the next category starts\n",
    "\n",
    "    _prev_col_category = None\n",
    "    _next_x_position = -BOX_PLOT_STEP\n",
    "    for col in _df.columns:\n",
    "        col_category = None\n",
    "\n",
    "        if col == 'total':\n",
    "            # Special case for 'total' column which is not listed in binary_independent_variables dict\n",
    "            col_category = 'total'\n",
    "        elif col in {'party status: other', 'other'}:\n",
    "            col_category = _prev_col_category\n",
    "        else:\n",
    "            # Try to find column name in the binary_independent_variables dictionary\n",
    "            # This gives us the category that this column belongs to\n",
    "            for var_category, var_values in binary_independent_variables.items():\n",
    "                if col in var_values:\n",
    "                    col_category = var_category\n",
    "\n",
    "        assert col_category is not None, f\"Could not find category for column {col}\"\n",
    "\n",
    "        # Create a small gap between box plots if the next boxplot belongs to a different category\n",
    "        if _prev_col_category is not None and col_category != _prev_col_category:\n",
    "            category_separator_x_positions.append(_next_x_position + (BOX_PLOT_STEP + GAP_BETWEEN_CATEGORIES) / 2)\n",
    "            _next_x_position += GAP_BETWEEN_CATEGORIES\n",
    "\n",
    "        _next_x_position += BOX_PLOT_STEP\n",
    "        _prev_col_category = col_category\n",
    "        box_plot_x_positions.append(_next_x_position)\n",
    "\n",
    "    return box_plot_x_positions, category_separator_x_positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Single Categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "for df_name, _df in dfs.items():\n",
    "\n",
    "    for dv, dv_name in dependent_variables.items():\n",
    "        plt.title(f\"distribution of {dv_name}\")\n",
    "\n",
    "        for biv_key, (biv_name, biv_false_value, biv_true_value) in binary_independent_variables.items():\n",
    "\n",
    "            combined_df = _df[dv].to_frame(name='total') #.rename(columns={dv: 'total'})\n",
    "\n",
    "            combined_df[biv_true_value] = _df[_df[biv_key] == True][dv]\n",
    "            combined_df[biv_false_value] = _df[_df[biv_key] == False][dv]\n",
    "\n",
    "            distribution_biv_other = _df[(_df[biv_key] != True) & (_df[biv_key] != False)][dv]\n",
    "            if distribution_biv_other.shape[0] != 0:\n",
    "                combined_df['other'] = distribution_biv_other\n",
    "\n",
    "            box_plot_x_positions, category_separator_x_positions = compute_dataframe_grouping(combined_df)\n",
    "\n",
    "            figwidth = PLOT_DEFAULT_WIDTH + len(combined_df.columns) * BOX_PLOT_WIDTH\n",
    "\n",
    "            combined_df.plot(kind='box', rot=45, showfliers=False, positions=box_plot_x_positions, widths=0.5, figsize=(figwidth, 6))\n",
    "\n",
    "\n",
    "            plt.title(f\"{df_name} by {biv_name}\")\n",
    "            plt.ylabel(dv_name)\n",
    "\n",
    "            # Set font sizes\n",
    "            plt.gca().yaxis.label.set_fontsize(FONT_SIZE_AXIS_LABEL)\n",
    "            plt.gca().title.set_fontsize(FONT_SIZE_TITLE)\n",
    "            for x_tick_label in plt.gca().get_xticklabels():\n",
    "                x_tick_label.set_fontsize(FONT_SIZE_X_TICK)\n",
    "\n",
    "            # Plot separators between categories\n",
    "            for category_separator_x_position in category_separator_x_positions:\n",
    "                plt.axvline(category_separator_x_position, linestyle='--', color='darkgray')\n",
    "\n",
    "            # change y_axis ticks so they don't say 1e6 at the top of the y_axis and coefficients on the ticks\n",
    "            # instead have it say million if the value is in the millions\n",
    "            current_y_ticks = plt.gca().get_yticks()\n",
    "            if max(current_y_ticks) > 10 ** 6:\n",
    "                plt.gca().set_yticklabels(['{:.0f}M'.format(x/10**6)  for x in current_y_ticks])\n",
    "\n",
    "            plt.savefig(f\"{figures_save_path}/boxplots/{df_name}-{dv}-{biv_name}.png\",\n",
    "                        dpi=300,\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "# for saving with log y-scale activate the following lines:\n",
    "#            plt.yscale('log')\n",
    "\n",
    "#            plt.savefig(f\"{figures_save_path}/boxplots/{df_name}-{dv}-{biv_name}-log_scale.png\",\n",
    "#                        dpi=300,\n",
    "#                        bbox_inches=\"tight\")\n",
    "\n",
    "#            plt.show()\n",
    "            plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### All-in-One with normal money"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "# TODO: group by category @Tobias\n",
    "\n",
    "for df_name, _df in dfs.items():\n",
    "\n",
    "    for dv, dv_name in dependent_variables.items():\n",
    "        combined_df = _df[dv].to_frame(name='total')\n",
    "\n",
    "        # Select only columns listed in binary_independent_variables\n",
    "        for biv_key, (biv_name, biv_false_value, biv_true_value) in binary_independent_variables.items():\n",
    "\n",
    "            combined_df[biv_true_value] = _df[_df[biv_key] == True][dv]\n",
    "            combined_df[biv_false_value] = _df[_df[biv_key] == False][dv]\n",
    "\n",
    "            distribution_biv_other = _df[(_df[biv_key] != True) & (_df[biv_key] != False)][dv]\n",
    "            if distribution_biv_other.shape[0] != 0:\n",
    "                combined_df[f\"{biv_name}: other\"] = distribution_biv_other\n",
    "\n",
    "        box_plot_x_positions, category_separator_x_positions = compute_dataframe_grouping(combined_df)\n",
    "        column_names = combined_df.columns\n",
    "        column_names = [COLUMN_LABEL_MAPPING[col_name]\n",
    "                        if col_name in COLUMN_LABEL_MAPPING\n",
    "                        else col_name\n",
    "                        for col_name\n",
    "                        in column_names]\n",
    "        combined_df.columns = column_names\n",
    "\n",
    "        combined_df.plot(kind='box', rot=45, figsize=(20, 4.8), showfliers=False, positions=box_plot_x_positions)\n",
    "\n",
    "        # Plot separators between categories\n",
    "        for category_separator_x_position in category_separator_x_positions:\n",
    "            plt.axvline(category_separator_x_position, linestyle='--', color='darkgray')\n",
    "\n",
    "        plt.title(f\"{df_name}\")\n",
    "        plt.ylabel(dv_name)\n",
    "\n",
    "        # Set font sizes\n",
    "        plt.gca().yaxis.label.set_fontsize(FONT_SIZE_AXIS_LABEL)\n",
    "        plt.gca().title.set_fontsize(FONT_SIZE_TITLE)\n",
    "        for x_tick_label in plt.gca().get_xticklabels():\n",
    "            x_tick_label.set_fontsize(FONT_SIZE_X_TICK)\n",
    "\n",
    "\n",
    "        # change y_axis ticks so they don't say 1e6 at the top of the y_axis and coefficients on the ticks\n",
    "        # instead have it say million if the value is in the millions\n",
    "        current_y_ticks = plt.gca().get_yticks()\n",
    "        if max(current_y_ticks) > 10 ** 6:\n",
    "            plt.gca().set_yticklabels(['{:.0f}M'.format(x/10**6)  for x in current_y_ticks])\n",
    "\n",
    "        # Add category labels centered below the respective column names\n",
    "        for i_category, (category, col_names) in enumerate(binary_independent_variables.items()):\n",
    "            if i_category < len(binary_independent_variables.keys()) - 1:\n",
    "                # Position of category label is computed by taking the middle positions of the\n",
    "                # left and right category separator line\n",
    "                category_label_x_position = (category_separator_x_positions[i_category] + category_separator_x_positions[i_category + 1]) / 2\n",
    "            else:\n",
    "                # Special case for the last category label since we don't have a separator line to the right of that\n",
    "                category_label_x_position = category_separator_x_positions[i_category] + GAP_BETWEEN_CATEGORIES / 2 + (len(col_names) - 1) * BOX_PLOT_STEP / 2\n",
    "\n",
    "            category_label_y_position = -CATEGORY_LABEL_POSITION* current_y_ticks[-1]\n",
    "            category_label = col_names[0]\n",
    "            plt.text(category_label_x_position, category_label_y_position, col_names[0], horizontalalignment='center', fontsize=15)\n",
    "\n",
    "\n",
    "        plt.savefig(f\"{figures_save_path}/boxplots/{df_name}-{dv}-all_in_one.png\",\n",
    "                    dpi=300,\n",
    "                    bbox_inches=\"tight\")\n",
    "\n",
    "# for saving with log y-scale activate the following lines:\n",
    "#        plt.yscale('log')\n",
    "\n",
    "#        plt.savefig(f\"{figures_save_path}/boxplots/{df_name}-{dv}-all_in_one-log_scale.png\",\n",
    "#                    dpi=300,\n",
    "#                    bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "#        plt.show()\n",
    "        plt.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Qualitative Analysis: Generate .csv files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns_to_investigate = ['sent_id', 'Speaker_name', 'is_coalition', 'is_mp', 'is_female', 'is_upper_house', 'is_chairperson', 'sentence','num_value', 'is_float-like', 'relative_uncertainty', 'is_about_money', 'has_approximator', 'approximators']\n",
    "\n",
    "# high number values\n",
    "df[columns_to_investigate].sort_values(by='num_value', ascending=False, inplace=False).iloc[:100].to_csv(f\"{qualitative_analysis_save_path}/high_number_values.csv\")\n",
    "\n",
    "# negative number values\n",
    "df[columns_to_investigate][df['num_value'] < 0].to_csv(f\"{qualitative_analysis_save_path}/negative_number_values.csv\")\n",
    "\n",
    "# low relative uncertainty\n",
    "df[columns_to_investigate].sort_values(by='relative_uncertainty', ascending=True, inplace=False).iloc[:100].to_csv(f\"{qualitative_analysis_save_path}/low_relative_uncertainty.csv\")\n",
    "\n",
    "# high relative uncertainty\n",
    "df[columns_to_investigate].sort_values(by='relative_uncertainty', ascending=False, inplace=False).iloc[:100].to_csv(f\"{qualitative_analysis_save_path}/low_relative_uncertainty.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Shit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['is_float-like']][columns_to_investigate].sort_values(by='num_value', ascending=False, inplace=False).iloc[:100].to_csv(f\"{qualitative_analysis_save_path}/float-likes--high_number_values.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['is_about_money']].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-Linguistics-py",
   "language": "python",
   "display_name": "Python [conda env:Linguistics] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
